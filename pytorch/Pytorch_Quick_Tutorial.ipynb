{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "generative_ai_disabled": true,
      "gpuType": "T4",
      "authorship_tag": "ABX9TyN0oYKe6SFk92V0NqN3YUYv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HarshiniAiyyer/Relearning/blob/main/Pytorch_Quick_Tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Tensor Basics\n",
        "\n",
        "- Multidimensional matrix containing elements of a single datatype."
      ],
      "metadata": {
        "id": "hxg-h4JKWITx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Imports"
      ],
      "metadata": {
        "id": "s3lyGBWxYkyF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "NH2tQJ0BNgvF"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### torch.empty\n",
        "\n",
        "- Initialize with no or dimensions of values"
      ],
      "metadata": {
        "id": "66EYUQxZWiI4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.empty(2)  #vector\n",
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L3xGFaL4Wl1-",
        "outputId": "1b9702e2-b0e2-499c-a454-34d8cb5bfa2a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([6.0321e-02, 4.3323e-41])"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "yz = torch.empty(2,3) # matrix\n",
        "\n",
        "yz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vZkwSynFWsCH",
        "outputId": "991266ff-3400-44dd-ecbb-6e2209de18dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[2.8728e-05, 0.0000e+00, 0.0000e+00],\n",
              "        [1.6951e-05, 1.1210e-43, 0.0000e+00]])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.empty(2,2,2)  #3d tensor\n",
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yo7O5EqPWyK_",
        "outputId": "f8381d8f-4b41-4445-ac4d-d46519d69bdc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[2.1919e-02, 4.3323e-41],\n",
              "         [2.1915e-02, 4.3323e-41]],\n",
              "\n",
              "        [[2.4293e-02, 4.3323e-41],\n",
              "         [2.3965e-02, 4.3323e-41]]])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.empty(2,2,2,2)\n",
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Z6QSZpAW4oQ",
        "outputId": "5b9d9af0-64e1-4215-a5ba-1fcf8f271ca5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[[3.0805e-06, 0.0000e+00],\n",
              "          [2.5032e-02, 4.3323e-41]],\n",
              "\n",
              "         [[0.0000e+00, 0.0000e+00],\n",
              "          [0.0000e+00, 0.0000e+00]]],\n",
              "\n",
              "\n",
              "        [[[0.0000e+00, 0.0000e+00],\n",
              "          [0.0000e+00, 0.0000e+00]],\n",
              "\n",
              "         [[0.0000e+00, 0.0000e+00],\n",
              "          [0.0000e+00, 0.0000e+00]]]])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### torch.rand\n",
        "\n",
        "- initializes with random numbers"
      ],
      "metadata": {
        "id": "F8BNXX1tXKYM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.rand(5,3)\n",
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2wzIErq1XPWU",
        "outputId": "c29fe0b4-3866-44f3-f2b3-d268ae0ce922"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.3420, 0.7289, 0.6394],\n",
              "        [0.5578, 0.1047, 0.8180],\n",
              "        [0.0807, 0.0078, 0.5093],\n",
              "        [0.7583, 0.7023, 0.3112],\n",
              "        [0.5150, 0.0427, 0.6080]])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### torch.zeros and torch.ones\n",
        "\n",
        "- fills the matrics with zeros or ones"
      ],
      "metadata": {
        "id": "yOIjrw6xYmM4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.zeros(4,3)\n",
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oaUpUDVZY_vU",
        "outputId": "ccc5814f-1777-4ac3-b573-6372db08d5ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 0., 0.],\n",
              "        [0., 0., 0.],\n",
              "        [0., 0., 0.],\n",
              "        [0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = torch.ones(2,3)\n",
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GbP7z9AuZHVu",
        "outputId": "7ce52f36-d781-4a08-c926-a030df800586"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 1., 1.],\n",
              "        [1., 1., 1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### torch.size(), torch.shape"
      ],
      "metadata": {
        "id": "v660xknTZP3f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"size\", y.size())\n",
        "print(\"shape\", y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ucIm1drZPpu",
        "outputId": "3ef79ee5-2bb3-4476-ce48-59b37f88dad3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "size torch.Size([2, 3])\n",
            "shape torch.Size([2, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### torch datatype"
      ],
      "metadata": {
        "id": "AEnfM6CzZwBD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(x.dtype)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dEmR412vaYc8",
        "outputId": "8f6bacf5-31d6-4605-f194-acd2d16b0735"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.float32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Specify datatype, float32 is usually the default"
      ],
      "metadata": {
        "id": "xYPfH2-maaq-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.zeros(5,3,dtype = torch.float16)\n",
        "print(x)\n",
        "\n",
        "print(x.dtype)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2J_T8lgCagcJ",
        "outputId": "2584cdc8-7555-4874-f1e0-25cc6e71869e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0., 0., 0.],\n",
            "        [0., 0., 0.],\n",
            "        [0., 0., 0.],\n",
            "        [0., 0., 0.],\n",
            "        [0., 0., 0.]], dtype=torch.float16)\n",
            "torch.float16\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Construct from different datatype\n",
        "\n",
        "- here we can use an array\n",
        "\n"
      ],
      "metadata": {
        "id": "F8CWizYAaqxG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.tensor([5.5,3])\n",
        "print(x,x.dtype)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JILlif68aqeh",
        "outputId": "00cc3ae8-ab6b-43a7-ebb9-a64ed5d68242"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([5.5000, 3.0000]) torch.float32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Requires grad\n",
        "\n",
        "- false by default.\n",
        "- if true, it tells pytorch, we need to calculate the gradient for the variable.\n",
        "- useful in later, when there is optimization in pytorch"
      ],
      "metadata": {
        "id": "ooNCZ398bGnz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.tensor([5.5,3], requires_grad=True)\n",
        "print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_JExm6U_b0Pe",
        "outputId": "80fe946c-62ba-496a-d839-427467027733"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([5.5000, 3.0000], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Operations with Tensors"
      ],
      "metadata": {
        "id": "qpDjfkEKb9Vp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.ones(2,2)\n",
        "y = torch.rand(2,2)\n",
        "print(x,y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WUwTcHKBb_xz",
        "outputId": "0f336bc4-4ca9-44db-ff46-9ae55d415063"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 1.],\n",
            "        [1., 1.]]) tensor([[0.3043, 0.5305],\n",
            "        [0.6256, 0.5227]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#elementwise and add function\n",
        "z = x+y\n",
        "torch.add(x,y)\n",
        "\n",
        "\n",
        "#inplace addition operation\n",
        "y.add_(x)\n",
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lC5Uy-rNcLi9",
        "outputId": "e46a17b3-38e0-4497-c818-1698c03123bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1.3043, 1.5305],\n",
            "        [1.6256, 1.5227]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#subtraction\n",
        "z = x - y\n",
        "z = torch.sub(x,y)\n",
        "\n",
        "#multiplication\n",
        "z = x - y\n",
        "z = torch.mul(x,y)\n",
        "\n",
        "#division\n",
        "z = x / y\n",
        "z = torch.div(x,y)"
      ],
      "metadata": {
        "id": "dc9IOUnBcnEm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Slicing"
      ],
      "metadata": {
        "id": "ssOdrFpzc5dd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.rand(5,3)\n",
        "print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PFM6DT_8c5Er",
        "outputId": "a9c50dd5-c034-452e-bbd1-84945666bfd3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.7039, 0.3450, 0.3592],\n",
            "        [0.7058, 0.2244, 0.0047],\n",
            "        [0.8720, 0.0793, 0.4089],\n",
            "        [0.4985, 0.0307, 0.5966],\n",
            "        [0.5639, 0.2824, 0.7586]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"x[:,0]\", x[:,0]) #all rows, column 0\n",
        "print(\"x[1,:]\", x[1,:]) #row 1, all columns\n",
        "print(\"x[1,1]\", x[1,1]) #element at 1,1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9-hYQL98dHB7",
        "outputId": "806ae2a7-56d8-48db-cbf6-94a1adfa80c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x[:,0] tensor([0.7039, 0.7058, 0.8720, 0.4985, 0.5639])\n",
            "x[1,:] tensor([0.7058, 0.2244, 0.0047])\n",
            "x[1,1] tensor(0.2244)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get the actual value, if there is only 1 element in the tensor\n",
        "\n",
        "print(\"x[1,1].item()\", x[1,1].item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XApHV9DXd_i2",
        "outputId": "72a88ea5-3419-4cc2-ce1b-f6668912c9e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x[1,1].item() 0.22435015439987183\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### reshape the tensor"
      ],
      "metadata": {
        "id": "Vyi4eN1seNAr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.randn(4,4)\n",
        "y = x.view(16)\n",
        "\n",
        "z = x.view(-1,8)  #size -1 is inferred from other dimensions\n",
        "\n",
        "print(x.size(), y.size(), z.size())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5aZMM3kKeDmM",
        "outputId": "73a675f7-67f2-447d-a00c-ba04a967ab79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 4]) torch.Size([16]) torch.Size([2, 8])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Numpy things\n",
        "\n",
        "Converting a torch tensor to numpy array and vice versa is very easy"
      ],
      "metadata": {
        "id": "6M_WFXS2ehdH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.ones(5)\n",
        "print(a)\n",
        "\n",
        "#convert to numpy\n",
        "b = a.numpy()\n",
        "print(b)\n",
        "print(type(b))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9VzHB4hCfHSU",
        "outputId": "ffafa770-f189-4a37-90c7-17d0c772fe1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1., 1., 1., 1., 1.])\n",
            "[1. 1. 1. 1. 1.]\n",
            "<class 'numpy.ndarray'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- if the given runtime is on a cpu, not a gpu, then they wud share the same location\n",
        "\n",
        "- then a wud be compeltely replaced by b."
      ],
      "metadata": {
        "id": "ZWGjRcGlfYxs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a.add_(1)\n",
        "print(a)\n",
        "print(b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g4Rwv0r7gLak",
        "outputId": "3ea65861-a5ff-4395-b32e-15e3eadc48cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([2., 2., 2., 2., 2.])\n",
            "[2. 2. 2. 2. 2.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### numpy to torch with .from_numpy()\n",
        "\n",
        "- replaces old with new, since they share the same location"
      ],
      "metadata": {
        "id": "ayLcMMY3gdRp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = np.ones(5)\n",
        "b = torch.from_numpy(a)\n",
        "print(a,b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z6xS-XIpgUvG",
        "outputId": "7675b6b8-7c74-4586-8b2f-6a04a3f961b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1. 1. 1. 1. 1.] tensor([1., 1., 1., 1., 1.], dtype=torch.float64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### torch.tensor()\n",
        "\n",
        "- unlike from_numpy, this creates an exact copy at a new location"
      ],
      "metadata": {
        "id": "gMbRL0f0gvUf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "c = torch.tensor(a)\n",
        "print(a,b,c)\n",
        "\n",
        "a += 2\n",
        "print(a,b,c)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6W8m95mfgu7f",
        "outputId": "073b085f-5e2e-46b3-d311-b1c1a846b10f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1. 1. 1. 1. 1.] tensor([1., 1., 1., 1., 1.], dtype=torch.float64) tensor([1., 1., 1., 1., 1.], dtype=torch.float64)\n",
            "[3. 3. 3. 3. 3.] tensor([3., 3., 3., 3., 3.], dtype=torch.float64) tensor([1., 1., 1., 1., 1.], dtype=torch.float64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### GPU Support\n",
        "\n",
        "all tensors are cpu by default\n",
        "\n",
        "we can also move them to the gpu if available\n",
        "\n",
        "or create them directly onto the gpu"
      ],
      "metadata": {
        "id": "E3dslT6ihIRV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dev = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "x = torch.rand(2, 2).to(dev) #move tensors to gpu device\n",
        "\n",
        "y = x.to(\"cpu\")\n",
        "z = x.to(\"cuda\")\n",
        "\n",
        "#directly create it in gpu #MORE EFFICIENT\n",
        "x = torch.rand(2,2, device = dev)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "collapsed": true,
        "id": "hO2TbkL6hKRz",
        "outputId": "baa15a7e-9cbd-428b-ac1f-15204e893897"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3498377784.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m#directly create it in gpu\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    410\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"CUDA_MODULE_LOADING\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m             \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"CUDA_MODULE_LOADING\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"LAZY\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 412\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    413\u001b[0m         \u001b[0;31m# Some of the queued calls may reentrantly call _lazy_init();\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0;31m# we need to just return without initializing in that case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##2. Autograd\n",
        "\n",
        "- a package that provides automatic differentiation for all ops on tensors.\n",
        "\n",
        "- torch.autograd computes vector jacobian product. or partial derivatives during chain rule\n",
        "\n",
        "- works when u set requires_grad = true"
      ],
      "metadata": {
        "id": "Cv4OF_ttiWQg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#requires_grad = true, it stores all operations on the tensor\n",
        "\n",
        "x = torch.randn(3, requires_grad=True)\n",
        "y = x + 2"
      ],
      "metadata": {
        "id": "Q0TuNb0thZOL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- y was created as a result of an operation, so it has a grad_fn attribute\n",
        "\n",
        "- grad_fn: references a function that has created the tensor"
      ],
      "metadata": {
        "id": "SiUiiSALj9OT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(x,y)\n",
        "print(y.grad_fn)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QfJw9AOkiL8_",
        "outputId": "83ef63cf-bf57-4163-bcec-b4aa45fbe026"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-0.1312, -0.4834, -0.5431], requires_grad=True) tensor([1.8688, 1.5166, 1.4569], grad_fn=<AddBackward0>)\n",
            "<AddBackward0 object at 0x78c429ac07c0>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "add backward is coz addition in backpropagation happened"
      ],
      "metadata": {
        "id": "oxbUKEahkS6H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Computing gradients with backpropagation\n",
        "\n",
        "- we finish our computation we can call .backward() and have all the gradients computed automatically\n",
        "\n",
        "- the gradient for this tensor will be accummulated into .grad attribute\n",
        "\n",
        "- its the partial derivative of the function wrt tensor"
      ],
      "metadata": {
        "id": "7PhcrrgMloxV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# random loss function, mean error here\n",
        "\n",
        "z = y * y * 3\n",
        "z = z.mean()\n",
        "\n",
        "print(z)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K5-oBIQhkV50",
        "outputId": "16665919-6442-4521-99bb-71a8fed8cdb5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(7.9152, grad_fn=<MeanBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(x.grad)\n",
        "z.backward()\n",
        "print(x.grad) #dz/dx #gradient of the loss wrt weights"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sSTczEJdktgc",
        "outputId": "8aa010d8-e45b-4880-9e13-26abe781e6f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n",
            "tensor([3.7377, 3.0332, 2.9138])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Important:\n",
        "\n",
        "- as we iterate epoch of epochs during our model training\n",
        "\n",
        "- then the gradient is calculated at every iteration.\n",
        "\n",
        "- backward() will eventually accumulate all the grad calculations together\n",
        "\n",
        "- which we dont want\n",
        "\n",
        "- so during optimization we ensure that the optimizer always turns grad to zero. optimzer.zero_grad()"
      ],
      "metadata": {
        "id": "QSw8FWXPmcfx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Stop a tensor from tracking gradient history\n",
        "\n",
        " - x.requires_grad(False)\n",
        " - x.detach()\n",
        " - wrap it in \"with torch.no_grad()\""
      ],
      "metadata": {
        "id": "V7ALWQKgoT6U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Linear Regression with Gradient Descent Autograd\n",
        "\n",
        "### Formula\n",
        "\n",
        "f(x) = w * x + b,\n",
        "- where w is  weights,\n",
        "- x is the datapoint and\n",
        "- b is bias\n",
        "\n"
      ],
      "metadata": {
        "id": "U-7t3HdirP5f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Eg: f(x) = 2*x here, b = 0"
      ],
      "metadata": {
        "id": "_lCMsCaUrmj4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Defining variables"
      ],
      "metadata": {
        "id": "rrGWbwgauDlB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#linear regression\n",
        "\n",
        "# f = w * x + b\n",
        "# here, f = 2 * x\n",
        "\n",
        "x = torch.tensor([1,2,3,4,5,6,7,8], dtype = torch.float32)\n",
        "y = torch.tensor([2,4,6,8,10,12,14,16], dtype = torch.float32)\n",
        "\n",
        "w = torch.tensor(0.0, dtype = torch.float32, requires_grad = True)\n",
        "\n",
        "print(x,y,w)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FV4g7pwFn1SD",
        "outputId": "b2786354-10f3-4192-8014-519093441ec1"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1., 2., 3., 4., 5., 6., 7., 8.]) tensor([ 2.,  4.,  6.,  8., 10., 12., 14., 16.]) tensor(0., requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Defining forward and loss function\n",
        "\n",
        "- Forward function is model output"
      ],
      "metadata": {
        "id": "aj4RrzLyuAq-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Training the model (Includes backward and weight updating)\n",
        "\n",
        "- The part where we update weights after gradient descent is called the optimizer. this is done by the optimizer function."
      ],
      "metadata": {
        "id": "rHkjcWbEuign"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# training data\n",
        "x = torch.tensor([1,2,3,4,5,6,7,8], dtype=torch.float32)\n",
        "y = torch.tensor([2,4,6,8,10,12,14,16], dtype=torch.float32)\n",
        "\n",
        "# weight parameter\n",
        "w = torch.tensor(0.0, dtype=torch.float32, requires_grad=True)\n",
        "\n",
        "# model\n",
        "def forward(x):\n",
        "    return w * x\n",
        "\n",
        "# MSE loss\n",
        "def loss(y, y_pred):\n",
        "    return ((y_pred - y)**2).mean()\n",
        "\n",
        "# training loop\n",
        "lr = 0.01\n",
        "epochs = 100\n",
        "\n",
        "for e in range(epochs):\n",
        "    # forward pass\n",
        "    y_pred = forward(x)\n",
        "\n",
        "    # compute loss\n",
        "    l = loss(y, y_pred)\n",
        "\n",
        "    # backward pass\n",
        "    l.backward()\n",
        "\n",
        "    # update weights (in-place so w remains leaf tensor)\n",
        "    with torch.no_grad():\n",
        "        w -= lr * w.grad\n",
        "\n",
        "    # reset gradients\n",
        "    w.grad.zero_()\n",
        "\n",
        "    if (e+1) % 10 == 0:\n",
        "        print(f\"epoch {e+1}: w = {w.item():.3f}, loss = {l.item():.3f}\")\n",
        "\n",
        "# test\n",
        "x_test = 5.0\n",
        "print(f\"Prediction after training: f({x_test}) = {forward(x_test).item():.3f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sA_1tvBnZY70",
        "outputId": "7f14236e-0d74-4bc0-d3f6-029b471ebfa1"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 10: w = 1.998, loss = 0.000\n",
            "epoch 20: w = 2.000, loss = 0.000\n",
            "epoch 30: w = 2.000, loss = 0.000\n",
            "epoch 40: w = 2.000, loss = 0.000\n",
            "epoch 50: w = 2.000, loss = 0.000\n",
            "epoch 60: w = 2.000, loss = 0.000\n",
            "epoch 70: w = 2.000, loss = 0.000\n",
            "epoch 80: w = 2.000, loss = 0.000\n",
            "epoch 90: w = 2.000, loss = 0.000\n",
            "epoch 100: w = 2.000, loss = 0.000\n",
            "Prediction after training: f(5.0) = 10.000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Model, Loss, Optimizer\n",
        "\n",
        "Parts of a Pytorch pipeline:\n",
        "\n",
        "(a) Design model (input, output, forward pass with different layers)\n",
        "\n",
        "(b) Construct loss and optimizer\n",
        "\n",
        "(c) training loop:\n",
        "- forward : compute prediction and loss\n",
        "- backward: compute gradients\n",
        "- update weights - with optimizer"
      ],
      "metadata": {
        "id": "VwRjbH5KdPNQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "#linear regression\n",
        "\n",
        "# f = w * x + b\n",
        "# here, f = 2 * x\n",
        "\n",
        "#0) training samples, take care of the shape\n",
        "\n",
        "x = torch.tensor([[1],[2],[3],[4],[5],[6],[7],[8]], dtype = torch.float32)\n",
        "y = torch.tensor([[2],[4],[6],[8],[10],[12],[14],[16]], dtype = torch.float32)\n",
        "\n",
        "n_samples, n_features = x.shape\n",
        "\n",
        "print(f'n_samples = {n_samples}, n_features = {n_features}')\n",
        "\n",
        "#0) create a test sample\n",
        "x_test = torch.tensor([5], dtype = torch.float32)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6grcPJN2esKZ",
        "outputId": "ae08c59c-89ba-497a-f307-2067b302807d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "n_samples = 8, n_features = 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#1. Design the model ; implement forward pass\n",
        "\n",
        "## use model = nn.Linear(input_size, output_size)\n",
        "\n",
        "class LinearRegression(nn.Module):\n",
        "  def __init__(self, input_dim, output_dim):\n",
        "    super(LinearRegression, self).__init__()\n",
        "\n",
        "    #define different layers\n",
        "\n",
        "    self.lin = nn.Linear(input_dim, output_dim)\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.lin(x)\n",
        "\n",
        "input_size, output_size = n_features, n_features\n",
        "\n",
        "model = LinearRegression(input_size, output_size)\n",
        "\n",
        "print(f\"Prediction before training: f({x_test}) = {model(x_test).item():.3f}\")\n",
        "\n",
        "\n",
        "#2) define loss and optimizer\n",
        "\n",
        "lr = 0.01\n",
        "nepochs = 100\n",
        "\n",
        "loss = nn.MSELoss()\n",
        "\n",
        "opt = torch.optim.SGD(model.parameters(), lr = lr)\n",
        "\n",
        "#3) training loop\n",
        "\n",
        "for e in range(nepochs):\n",
        "\n",
        "  #predict = forward pass with our model\n",
        "  ypred = model(x)\n",
        "\n",
        "  #loss\n",
        "  l = loss(y, ypred)\n",
        "\n",
        "  #calcualte gradients = backend pass\n",
        "  l.backward()\n",
        "\n",
        "  #update weights\n",
        "  opt.step()\n",
        "\n",
        "  #zero the gradients after updating\n",
        "\n",
        "  opt.zero_grad()\n",
        "\n",
        "  if(e + 1) % 10 == 0:\n",
        "    w,b = model.parameters() #unpack parameters\n",
        "\n",
        "    print('epoch', e + 1, ': w = ', w[0][0].item(), ' loss = ', l.item())\n",
        "\n",
        "\n",
        "print(f\"Prediction after training: f({x_test}) = {forward(x_test).item():.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wMWk19K7g9MR",
        "outputId": "ff5bcf37-99ac-4c88-ae69-4876b63f2592"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction before training: f(tensor([5.])) = 4.477\n",
            "epoch 10 : w =  1.823476791381836  loss =  0.20307624340057373\n",
            "epoch 20 : w =  1.830997347831726  loss =  0.18741841614246368\n",
            "epoch 30 : w =  1.8376249074935913  loss =  0.1730078011751175\n",
            "epoch 40 : w =  1.8439922332763672  loss =  0.15970534086227417\n",
            "epoch 50 : w =  1.8501099348068237  loss =  0.1474255919456482\n",
            "epoch 60 : w =  1.8559876680374146  loss =  0.13609015941619873\n",
            "epoch 70 : w =  1.8616349697113037  loss =  0.12562628090381622\n",
            "epoch 80 : w =  1.867060661315918  loss =  0.11596684902906418\n",
            "epoch 90 : w =  1.8722736835479736  loss =  0.10705007612705231\n",
            "epoch 100 : w =  1.8772823810577393  loss =  0.09881921857595444\n",
            "Prediction after training: f(tensor([5.])) = 9.386\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Simple Neural Network (with 1 hidden layer)\n",
        "\n",
        "- GPU, Datasets, DataLoader, Transforms, Neural Net, Training and Evaluation"
      ],
      "metadata": {
        "id": "HViTgJitnVay"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#gpu\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "BAl9NyJ8ndqu"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Starting with MNIST here.\n",
        "\n",
        "We will make a CNN."
      ],
      "metadata": {
        "id": "n2OuFci7p0y_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Hyperparameters"
      ],
      "metadata": {
        "id": "mph9GzuJqa33"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#hyper parameters\n",
        "\n",
        "input_size = 784  #28x28 pixels flattened\n",
        "hidden_size = 500   #no of hidden layer neurons\n",
        "num_classes = 10\n",
        "num_epochs = 2\n",
        "batch_size = 100\n",
        "lr = 0.001"
      ],
      "metadata": {
        "id": "jbASpB8JpkQe"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Datasets and Dataloader"
      ],
      "metadata": {
        "id": "qT_Rw2CKqciE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "traind = torchvision.datasets.MNIST(root = './data',\n",
        "                                    train = True,\n",
        "                                    transform = transforms.ToTensor(),\n",
        "                                    download = True)\n",
        "\n",
        "\n",
        "testd = torchvision.datasets.MNIST(root = './data',\n",
        "                                    train = False,\n",
        "                                    transform = transforms.ToTensor())\n",
        "\n",
        "#data loader\n",
        "trainl = torch.utils.data.DataLoader(dataset = traind, batch_size = batch_size,\n",
        "                                     shuffle = True)\n",
        "\n",
        "testl = torch.utils.data.DataLoader(dataset = testd, batch_size = batch_size,\n",
        "                                     shuffle = False)\n",
        "\n",
        "\n",
        "#simply, shows a batch of the sample data - an iterator\n",
        "examples = iter(testl)\n",
        "\n",
        "exampledata, exampletarget = next(examples)\n",
        "\n",
        "for i in range(6):\n",
        "  plt.subplot(2,3,i+1)\n",
        "  plt.subplot(2,3,i+1)\n",
        "  plt.imshow(exampledata[i][0], cmap = 'gray')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 480
        },
        "id": "r2MQt5faqgry",
        "outputId": "6bcd08c7-a42d-429b-dbad-c170798326b5"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:00<00:00, 20.7MB/s]\n",
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 495kB/s]\n",
            "100%|██████████| 1.65M/1.65M [00:00<00:00, 4.62MB/s]\n",
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 9.23MB/s]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 6 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training the model"
      ],
      "metadata": {
        "id": "6eBjgeTxsWct"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#STEP 1: DEFINING EVERYTHING + FORWARD FUNCTION\n",
        "\n",
        "#1 hidden layer\n",
        "\n",
        "class NeuralNet(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size, num_classes):\n",
        "    super(NeuralNet, self). __init__()\n",
        "    self.l1 = nn.Linear(input_size, hidden_size)\n",
        "    self.relu = nn.ReLU()\n",
        "    self.l2 = nn.Linear(hidden_size, num_classes)\n",
        "\n",
        "  def forward(self, x):\n",
        "    out = self.l1(x)\n",
        "    out = self.relu(out)\n",
        "    out = self.l2(out)\n",
        "\n",
        "    #no activation or softmax at the end\n",
        "    #we already define this separately\n",
        "    return out\n",
        "\n",
        "\n",
        "model = NeuralNet(input_size, hidden_size, num_classes).to(device) #making the device to the gpu itself\n",
        "\n",
        "#STEP 2: LOSS AND OPTIMIZER\n",
        "\n",
        "criter = nn.CrossEntropyLoss()\n",
        "#cross entropy wants only raw values from the forward function so we dont use any softmax or anything in that function\n",
        "\n",
        "op = torch.optim.Adam(model.parameters(), lr = lr)\n",
        "\n",
        "\n",
        "#STEP 3: TRAIN THE MODEL\n",
        "\n",
        "steps = len(trainl)\n",
        "\n",
        "for e in range(num_epochs):\n",
        "  for i, (images, labels) in enumerate(trainl):\n",
        "\n",
        "    #origin shape: [100, 1, 28, 28]\n",
        "    #resized: [100, 784]\n",
        "\n",
        "    #RESHAPE AND ADD TO DEVICE\n",
        "    images = images.reshape(-1, 28*28).to(device)\n",
        "    labels = labels.to(device)\n",
        "\n",
        "    #FORWARD PASS + LOSS\n",
        "    outputs = model(images)\n",
        "    loss = criter(outputs, labels)\n",
        "\n",
        "    #BACKWARD\n",
        "\n",
        "    loss.backward()\n",
        "    op.step()\n",
        "    op.zero_grad()\n",
        "\n",
        "    if (i+1) % 100 == 0:\n",
        "      print(f'Epoch [{e+1} / {num_epochs}], Step [{i+1} / {steps}], Loss: {loss.item():.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8TJqxW-t2EC6",
        "outputId": "6ffca540-f3f9-4de4-fcc3-a5b21fc8b5a2"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1 / 2], Step [100 / 600], Loss: 0.3697\n",
            "Epoch [1 / 2], Step [200 / 600], Loss: 0.2090\n",
            "Epoch [1 / 2], Step [300 / 600], Loss: 0.2476\n",
            "Epoch [1 / 2], Step [400 / 600], Loss: 0.3726\n",
            "Epoch [1 / 2], Step [500 / 600], Loss: 0.2666\n",
            "Epoch [1 / 2], Step [600 / 600], Loss: 0.1467\n",
            "Epoch [2 / 2], Step [100 / 600], Loss: 0.1515\n",
            "Epoch [2 / 2], Step [200 / 600], Loss: 0.0987\n",
            "Epoch [2 / 2], Step [300 / 600], Loss: 0.0880\n",
            "Epoch [2 / 2], Step [400 / 600], Loss: 0.0823\n",
            "Epoch [2 / 2], Step [500 / 600], Loss: 0.1871\n",
            "Epoch [2 / 2], Step [600 / 600], Loss: 0.1839\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Testing the model"
      ],
      "metadata": {
        "id": "5g1KXih97WV3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#test the model: no need to compute the gradients\n",
        "\n",
        "with torch.no_grad():\n",
        "  ncorrect = 0\n",
        "  nsamples = len(testl.dataset)\n",
        "\n",
        "  for images, labels in testl:\n",
        "\n",
        "    #origin shape: [100, 1, 28, 28]\n",
        "    #resized: [100, 784]\n",
        "\n",
        "    #RESHAPE AND ADD TO DEVICE\n",
        "    images = images.reshape(-1, 28*28).to(device)\n",
        "    labels = labels.to(device)\n",
        "\n",
        "    #FORWARD PASS\n",
        "    outputs = model(images)\n",
        "\n",
        "    #MAX RETURNS (OUTPUT_VALUE, INDEX)\n",
        "    _, predicted = torch.max(outputs, 1 )\n",
        "    ncorrect += (predicted == labels).sum().item()\n",
        "\n",
        "\n",
        "#CALCULATE ACCURACY\n",
        "acc = ncorrect / nsamples\n",
        "\n",
        "print(f'accuracy of the network on the {nsamples} test imagesL {100*acc} %')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Edb3Pja84oP-",
        "outputId": "c7805581-83ba-401e-ef8f-540adc234a01"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy of the network on the 10000 test imagesL 97.22 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##5. CNN\n",
        "\n",
        "We will use the CIFAR10 dataset\n",
        "\n",
        "- Convolutional Layers\n",
        "- Max Pooling\n",
        "- Save / Load Model"
      ],
      "metadata": {
        "id": "cw1KCfMn85Am"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Imports"
      ],
      "metadata": {
        "id": "tm2fZHDMEGhf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "#HYPER PARAMS\n",
        "numepochs = 10\n",
        "batchsize = 32\n",
        "lr = 0.001\n",
        "\n",
        "#dataset has PILImage images of range [0,1]\n",
        "\n",
        "#so we transform to Tensors of normalized range [-1,1]\n",
        "\n",
        "trans = transforms.Compose(\n",
        "    [transforms.ToTensor(), #this is mean, and this is std\n",
        "     transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))]\n",
        ") #normalizing the color channels here"
      ],
      "metadata": {
        "id": "FCL9kkqH84r_"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset and Dataloaders"
      ],
      "metadata": {
        "id": "mQSqkJFEEIXz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "traind = torchvision.datasets.CIFAR10(root = './data',\n",
        "                                    train = True,\n",
        "                                    transform = transforms.ToTensor(),\n",
        "                                    download = True)\n",
        "\n",
        "\n",
        "testd = torchvision.datasets.CIFAR10(root = './data',\n",
        "                                    train = False,\n",
        "                                    transform = transforms.ToTensor())\n",
        "\n",
        "#data loader\n",
        "trainl = torch.utils.data.DataLoader(dataset = traind, batch_size = batch_size,\n",
        "                                     shuffle = True)\n",
        "\n",
        "testl = torch.utils.data.DataLoader(dataset = testd, batch_size = batch_size,\n",
        "                                     shuffle = False)\n",
        "\n",
        "classes = ('plane','car','bird','cat','deer','dog', 'frog','horse','ship','truck')\n",
        "\n",
        "#display image samples\n",
        "\n",
        "def imshow(imgs):\n",
        "  imgs = imgs + 2 / 0.5  #unnormalize\n",
        "  npimgs = imgs.numpy()\n",
        "  plt.imshow(np.transpose(npimgs, (1,2,0)))\n",
        "  plt.show()\n",
        "\n",
        "dataiter = iter(trainl)\n",
        "images, labels = next(dataiter)\n",
        "img_grid = torchvision.utils.make_grid(images[0:25], nrow=5)\n",
        "imshow(img_grid)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 471
        },
        "collapsed": true,
        "id": "BBf_xLTVEKbI",
        "outputId": "aed15838-3cc5-41bd-8a52-e093d244b886"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [4.0..5.0].\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Defining the network"
      ],
      "metadata": {
        "id": "2GRJ_29xFZ7F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ConvNet(nn.Module):\n",
        "    def __init__(self): #define layers\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 32, 3)  #32 here is the output\n",
        "        self.pool = nn.MaxPool2d(2, 2) #reduce size of image\n",
        "        self.conv2 = nn.Conv2d(32, 64, 3) #so 32 becomes the input here. and so on.\n",
        "        self.conv3 = nn.Conv2d(64, 64, 3)\n",
        "        self.fc1 = nn.Linear(64*4*4, 64) #linear -> because classification\n",
        "        self.fc2 = nn.Linear(64, 10) #10 here because 10 classes\n",
        "\n",
        "    def forward(self, x):   #apply the layers\n",
        "        # N, 3, 32, 32\n",
        "        x = F.relu(self.conv1(x))   # -> N, 32, 30, 30\n",
        "        x = self.pool(x)            # -> N, 32, 15, 15  #pooling made it 30 to 15, almost half\n",
        "        x = F.relu(self.conv2(x))   # -> N, 64, 13, 13\n",
        "        x = self.pool(x)            # -> N, 64, 6, 6\n",
        "        x = F.relu(self.conv3(x))   # -> N, 64, 4, 4\n",
        "        x = torch.flatten(x, 1)     # -> N, 1024\n",
        "        x = F.relu(self.fc1(x))     # -> N, 64\n",
        "        x = self.fc2(x)             # -> N, 10\n",
        "        return x\n",
        "\n",
        "model = ConvNet().to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "n_total_steps = len(trainl)\n",
        "for epoch in range(num_epochs):\n",
        "\n",
        "    running_loss = 0.0\n",
        "\n",
        "    for i, (images, labels) in enumerate(trainl):\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward and optimize\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    print(f'[{epoch + 1}] loss: {running_loss / n_total_steps:.3f}')\n",
        "\n",
        "print('Finished Training')\n",
        "PATH = './cnn.pth'\n",
        "\n",
        "#stores the dictionary with only the parameters\n",
        "torch.save(model.state_dict(), PATH)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hrMtuuVEFcVl",
        "outputId": "78a41bda-42b7-46a2-b13a-e79b28ee91b1"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1] loss: 1.740\n",
            "[2] loss: 1.409\n",
            "Finished Training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Important: Since we stored only the paramters in the above cell and not the model, in the next code cell, we define a new model."
      ],
      "metadata": {
        "id": "jHeVAXIKHLUb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_model = ConvNet()\n",
        "loaded_model.load_state_dict(torch.load(PATH)) # it takes the loaded dictionary, not the path file itself\n",
        "loaded_model.to(device)\n",
        "loaded_model.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "    n_correct = 0\n",
        "    n_correct2 = 0\n",
        "    n_samples = len(testl.dataset)\n",
        "\n",
        "    for images, labels in testl:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(images)\n",
        "\n",
        "        # max returns (value ,index)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        n_correct += (predicted == labels).sum().item()\n",
        "\n",
        "        outputs2 = loaded_model(images)\n",
        "        _, predicted2 = torch.max(outputs2, 1)\n",
        "        n_correct2 += (predicted2 == labels).sum().item()\n",
        "\n",
        "    acc = 100.0 * n_correct / n_samples\n",
        "    print(f'Accuracy of the model: {acc} %')\n",
        "\n",
        "    acc = 100.0 * n_correct2 / n_samples\n",
        "    print(f'Accuracy of the loaded model: {acc} %')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AOGB2zyuHUUB",
        "outputId": "a63a2d17-69f3-43e4-abae-7ee045026ca8"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the model: 53.05 %\n",
            "Accuracy of the loaded model: 53.05 %\n"
          ]
        }
      ]
    }
  ]
}